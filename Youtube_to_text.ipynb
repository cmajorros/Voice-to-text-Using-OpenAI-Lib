{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmajorros/Voice-to-text-Using-OpenAI-Lib/blob/main/Youtube_to_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl3IxDMdX13_",
        "outputId": "6750bd74-d170-4148-de45-aaab296258a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting yt_dlp\n",
            "  Downloading yt_dlp-2024.7.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt_dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2024.6.2)\n",
            "Collecting mutagen (from yt_dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt_dlp)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests<3,>=2.32.2 (from yt_dlp)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt_dlp) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt_dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt_dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt_dlp) (3.7)\n",
            "Installing collected packages: brotli, websockets, requests, pycryptodomex, mutagen, yt_dlp\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.20.0 requests-2.32.3 websockets-12.0 yt_dlp-2024.7.2\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.10.4-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.6.2)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.10.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube\n",
        "!pip install yt_dlp\n",
        "!pip install SpeechRecognition\n",
        "import os\n",
        "import pytube\n",
        "import yt_dlp\n",
        "import speech_recognition as sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xymTyhY-Xz03"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H0qJPzsXz7t",
        "outputId": "ca3ed1e0-9ddd-4b1d-fed9-dd5b59d33812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['https://www.youtube.com/watch?v=khXNETeYyhU', 'https://www.youtube.com/watch?v=6hQs3Lm3hSE', 'https://www.youtube.com/watch?v=JdoobW_2jIk', 'https://www.youtube.com/watch?v=BXrJRiQoYcA', 'https://www.youtube.com/watch?v=_fr6PO6iMfo', 'https://www.youtube.com/watch?v=D-FUYDAlGYU', 'https://www.youtube.com/watch?v=e-0j5ozWNAE', 'https://www.youtube.com/watch?v=2_7dDBK3Jvo', 'https://www.youtube.com/watch?v=fLsgoIXuZcQ', 'https://www.youtube.com/watch?v=4iT5lyxilIg', 'https://www.youtube.com/watch?v=V0HwGnC1rU8', 'https://www.youtube.com/watch?v=mAIH3hUoxEE', 'https://www.youtube.com/watch?v=7qqJYxZqauQ', 'https://www.youtube.com/watch?v=QPCvVy0QBsA', 'https://www.youtube.com/watch?v=cafjAk7t5MM', 'https://www.youtube.com/watch?v=6FNaEUGooZE', 'https://www.youtube.com/watch?v=sr4S9SVcTHE', 'https://www.youtube.com/watch?v=5RJ_pZrV3VY', 'https://www.youtube.com/watch?v=grZbws1Kw_Q', 'https://www.youtube.com/watch?v=kGfUIOK87V8', 'https://www.youtube.com/watch?v=sM1QMz33HC4', 'https://www.youtube.com/watch?v=GrlRuOELJRw', 'https://www.youtube.com/watch?v=DTG5XzsxgQw', 'https://www.youtube.com/watch?v=cnLZZY8GhE0', 'https://www.youtube.com/watch?v=Bv_j6pHoPyI', 'https://www.youtube.com/watch?v=Ym4LP-7GGRE', 'https://www.youtube.com/watch?v=QBfASI3z8S4', 'https://www.youtube.com/watch?v=HbpdnJv2TKc', 'https://www.youtube.com/watch?v=6igatxnjU3s', 'https://www.youtube.com/watch?v=aY1rno5Gv54', 'https://www.youtube.com/watch?v=xtmMVLBIS-M', 'https://www.youtube.com/watch?v=UWaYrttT5OQ', 'https://www.youtube.com/watch?v=aFvxwKokUEg', 'https://www.youtube.com/watch?v=jvy3aoy462k', 'https://www.youtube.com/watch?v=vmPvZ_YRSgs', 'https://www.youtube.com/watch?v=7MJHmk2aZu8', 'https://www.youtube.com/watch?v=Un3mciXhPVY', 'https://www.youtube.com/watch?v=xrYKMj-MyYw', 'https://www.youtube.com/watch?v=RY0SSvSUkMA', 'https://www.youtube.com/watch?v=jmfUGRZhFlM', 'https://www.youtube.com/watch?v=mqv_jzohEAE', 'https://www.youtube.com/watch?v=CdZy3LivkhQ', 'https://www.youtube.com/watch?v=LDHFY9xTzls', 'https://www.youtube.com/watch?v=J1xm3VoVkaU', 'https://www.youtube.com/watch?v=vHjA-RoQMnU', 'https://www.youtube.com/watch?v=vFTI087HYNE', 'https://www.youtube.com/watch?v=qxEWAKyiNAc', 'https://www.youtube.com/watch?v=5G-N7mEDDnc', 'https://www.youtube.com/watch?v=6y2GS2BDmZA', 'https://www.youtube.com/watch?v=JxVCF_JdREg', 'https://www.youtube.com/watch?v=WQiiuTrcCeg', 'https://www.youtube.com/watch?v=lYjYE5wKHVI', 'https://www.youtube.com/watch?v=HNkPQtfzXK0', 'https://www.youtube.com/watch?v=3FDvHAl_ilw', 'https://www.youtube.com/watch?v=fPsGaJV4T_4', 'https://www.youtube.com/watch?v=Dw_al_26F6o', 'https://www.youtube.com/watch?v=ko6LzlFgjI0', 'https://www.youtube.com/watch?v=4eh7OTfMln8', 'https://www.youtube.com/watch?v=lk_sfZq-hrU', 'https://www.youtube.com/watch?v=AH0z0B9ErKs', 'https://www.youtube.com/watch?v=gEZkFF2kokk', 'https://www.youtube.com/watch?v=Yk6bKgphj1Q', 'https://www.youtube.com/watch?v=8VL4ZPLFUYI', 'https://www.youtube.com/watch?v=GwtWRUSEjk4', 'https://www.youtube.com/watch?v=YHPki3D9Prc', 'https://www.youtube.com/watch?v=zAWVE0TwMiU', 'https://www.youtube.com/watch?v=N_UxTpOm6Mg', 'https://www.youtube.com/watch?v=f6up5x_iRbI', 'https://www.youtube.com/watch?v=tXGDmqjmcTs']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import yt_dlp\n",
        "import speech_recognition as sr\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Extract video URLs from the YouTube channel using yt-dlp\n",
        "def get_video_urls(channel_url):\n",
        "    ydl_opts = {\n",
        "        'extract_flat': True,\n",
        "        'quiet': True,\n",
        "        'force_generic_extractor': True,\n",
        "    }\n",
        "    video_urls = []\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info = ydl.extract_info(channel_url, download=False)\n",
        "            entries = info.get('entries', [])\n",
        "            video_urls = [entry['url'] for entry in entries if entry.get('url')]\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching video URLs: {e}\")\n",
        "    return video_urls\n",
        "\n",
        "# Step 2: Download the audio from each video\n",
        "def download_audio(video_url, output_path=\"audio\"):\n",
        "    try:\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'wav',\n",
        "                'preferredquality': '192',\n",
        "            }],\n",
        "            'outtmpl': os.path.join(output_path, '%(id)s.%(ext)s'),\n",
        "            'quiet': True,\n",
        "        }\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([video_url])\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading audio: {e}\")\n",
        "\n",
        "# Step 3: Convert audio to text using speech recognition\n",
        "def audio_to_text(audio_file):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(audio_file) as source:\n",
        "        audio = recognizer.record(source)\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        return \"Audio unintelligible\"\n",
        "    except sr.RequestError as e:\n",
        "        return f\"Error with the recognition service: {e}\"\n",
        "\n",
        "def process_channel_videos(channel_url):\n",
        "    video_urls = get_video_urls(channel_url)\n",
        "    os.makedirs('audio', exist_ok=True)\n",
        "    os.makedirs('transcripts', exist_ok=True)\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for video_url in video_urls:\n",
        "        print(f\"Processing {video_url}...\")\n",
        "        download_audio(video_url)\n",
        "\n",
        "        video_id = video_url.split('=')[-1]\n",
        "        audio_file = f\"audio/{video_id}.wav\"\n",
        "        if os.path.exists(audio_file):\n",
        "            transcript = audio_to_text(audio_file)\n",
        "            with open(f\"transcripts/{video_id}.txt\", 'w') as f:\n",
        "                f.write(transcript)\n",
        "\n",
        "        # Add video ID and URL to data list\n",
        "        data.append({'video_id': video_id, 'video_url': video_url})\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    print(df)\n",
        "    return df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    channel_url = \"https://www.youtube.com/@Preset-io\"\n",
        "    video_urls = get_video_urls(channel_url)\n",
        "    print(video_urls)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_7cepWqCEGh",
        "outputId": "a3f191fc-3b47-4122-cc8a-4cc94463e8da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            URL Upload Date\n",
            "0   https://www.youtube.com/watch?v=2_7dDBK3Jvo  2023-12-20\n",
            "1   https://www.youtube.com/watch?v=fLsgoIXuZcQ  2023-12-20\n",
            "2   https://www.youtube.com/watch?v=4iT5lyxilIg  2023-11-15\n",
            "3   https://www.youtube.com/watch?v=V0HwGnC1rU8  2023-10-26\n",
            "4   https://www.youtube.com/watch?v=mAIH3hUoxEE  2023-10-24\n",
            "5   https://www.youtube.com/watch?v=7qqJYxZqauQ  2023-09-01\n",
            "6   https://www.youtube.com/watch?v=QPCvVy0QBsA  2023-08-24\n",
            "7   https://www.youtube.com/watch?v=cafjAk7t5MM  2023-08-11\n",
            "8   https://www.youtube.com/watch?v=6FNaEUGooZE  2023-07-13\n",
            "9   https://www.youtube.com/watch?v=sr4S9SVcTHE  2023-06-07\n",
            "10  https://www.youtube.com/watch?v=5RJ_pZrV3VY  2023-05-24\n",
            "11  https://www.youtube.com/watch?v=grZbws1Kw_Q  2023-05-12\n",
            "12  https://www.youtube.com/watch?v=kGfUIOK87V8  2023-05-10\n",
            "13  https://www.youtube.com/watch?v=sM1QMz33HC4  2023-04-21\n",
            "14  https://www.youtube.com/watch?v=GrlRuOELJRw  2023-03-15\n",
            "15  https://www.youtube.com/watch?v=DTG5XzsxgQw  2023-01-25\n",
            "16  https://www.youtube.com/watch?v=cnLZZY8GhE0  2023-01-05\n"
          ]
        }
      ],
      "source": [
        "#!pip install pytube\n",
        "from pytube import YouTube\n",
        "# Function to get upload date\n",
        "def get_upload_date(video_url):\n",
        "    try:\n",
        "        yt = YouTube(video_url)\n",
        "        return yt.publish_date\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Get upload dates for all videos\n",
        "data = []\n",
        "for url in video_urls:\n",
        "    date = get_upload_date(url)\n",
        "    if date and date > pd.Timestamp('2023-01-01') and date < pd.Timestamp('2024-01-01') :\n",
        "        data.append((url, date))\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data, columns=['URL', 'Upload Date'])\n",
        "\n",
        "# Show the DataFrame\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuzWKyvQBxji",
        "outputId": "3eb70a3d-46ef-43de-faa4-6cbe18c1b9b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Writing audio in /content/downloads/Navigating the Landscape of a Fully Open Source Data Stack in 2023.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Navigating the Landscape of a Fully Open Source Data Stack in 2023.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Open Source BI FTW   Building Compelling Dashboards with Apache Superset.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Open Source BI FTW   Building Compelling Dashboards with Apache Superset.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Enhancing Custom Visualization Plugins in Apache Superset (Part 1 Overview).mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Enhancing Custom Visualization Plugins in Apache Superset (Part 1 Overview).mp3\n",
            "MoviePy - Writing audio in /content/downloads/Preset Brief Demo August 2023.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Preset Brief Demo August 2023.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Live Demo Superset 101.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Live Demo Superset 101.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Superset 30 Virtual Meetup.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Superset 30 Virtual Meetup.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Deep Dive The Advantages of Open Source BI.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Deep Dive The Advantages of Open Source BI.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Apache Superset Dashboard Filters 101.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Apache Superset Dashboard Filters 101.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Live Demo Syncing databases datasets and metrics from dbt.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Live Demo Syncing databases datasets and metrics from dbt.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Embedding Dashboards with Superset.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Embedding Dashboards with Superset.mp3\n",
            "MoviePy - Writing audio in /content/downloads/GPT x Superset.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/GPT x Superset.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Superset 210 Meetup.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Superset 210 Meetup.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Apache Superset Overview Video.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Apache Superset Overview Video.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Customizing dashboards CSS Color palettes and Theming.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Customizing dashboards CSS Color palettes and Theming.mp3\n",
            "MoviePy - Writing audio in /content/downloads/The State of Drilling in Supeset.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/The State of Drilling in Supeset.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Apache Superset 2022 Recap.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Apache Superset 2022 Recap.mp3\n",
            "MoviePy - Writing audio in /content/downloads/Preset Customizable BI for the Modern Data Stack.mp3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "Video downloaded and audio extracted to /content/downloads/Preset Customizable BI for the Modern Data Stack.mp3\n"
          ]
        }
      ],
      "source": [
        "from pytube import YouTube\n",
        "from moviepy.editor import *\n",
        "import os\n",
        "# Directory to save downloads\n",
        "download_dir = 'downloads'\n",
        "os.makedirs(download_dir, exist_ok=True)\n",
        "\n",
        "def download_and_extract_audio(video_url, output_path):\n",
        "    try:\n",
        "        # Download video\n",
        "        yt = YouTube(video_url)\n",
        "        video_stream = yt.streams.filter(file_extension='mp4').first()\n",
        "        video_path = video_stream.download(output_path=output_path)\n",
        "\n",
        "        # Extract audio from video\n",
        "        video = VideoFileClip(video_path)\n",
        "        audio_path = os.path.splitext(video_path)[0] + '.mp3'\n",
        "        audio = video.audio\n",
        "        audio.write_audiofile(audio_path)\n",
        "        audio.close()\n",
        "        video.close()\n",
        "\n",
        "        print(f\"Video downloaded and audio extracted to {audio_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred for {video_url}: {e}\")\n",
        "\n",
        "# Loop through DataFrame and process each YouTube URL\n",
        "for index, row in df.iterrows():\n",
        "    video_url = row['URL']\n",
        "    download_and_extract_audio(video_url, download_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkub3qZeJ5J2"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1bnl8xYLSyJ",
        "outputId": "e6ee7fb0-68a0-4fa2-8183-db9259b80973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.15.4)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801359 sha256=4552edc6e7308831d8426343662df607dee48ad81d2a49894c50601f03b1b3a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHoz0t0fosJZ",
        "outputId": "88a5de51-9d0f-4b49-b0b7-9e5afc627b6d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 61.8MiB/s]\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Navigating the Landscape of a Fully Open Source Data Stack in 2023.mp3 to text and saved to content/speech_conversion/Navigating the Landscape of a Fully Open Source Data Stack in 2023.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Apache Superset Overview Video.mp3 to text and saved to content/speech_conversion/Apache Superset Overview Video.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Deep Dive The Advantages of Open Source BI.mp3 to text and saved to content/speech_conversion/Deep Dive The Advantages of Open Source BI.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Customizing dashboards CSS Color palettes and Theming.mp3 to text and saved to content/speech_conversion/Customizing dashboards CSS Color palettes and Theming.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Live Demo Superset 101.mp3 to text and saved to content/speech_conversion/Live Demo Superset 101.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Apache Superset 2022 Recap.mp3 to text and saved to content/speech_conversion/Apache Superset 2022 Recap.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Preset Brief Demo August 2023.mp3 to text and saved to content/speech_conversion/Preset Brief Demo August 2023.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Enhancing Custom Visualization Plugins in Apache Superset (Part 1 Overview).mp3 to text and saved to content/speech_conversion/Enhancing Custom Visualization Plugins in Apache Superset (Part 1 Overview).txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted The State of Drilling in Supeset.mp3 to text and saved to content/speech_conversion/The State of Drilling in Supeset.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Superset 30 Virtual Meetup.mp3 to text and saved to content/speech_conversion/Superset 30 Virtual Meetup.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Embedding Dashboards with Superset.mp3 to text and saved to content/speech_conversion/Embedding Dashboards with Superset.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Open Source BI FTW   Building Compelling Dashboards with Apache Superset.mp3 to text and saved to content/speech_conversion/Open Source BI FTW   Building Compelling Dashboards with Apache Superset.txt\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converted Apache Superset Dashboard Filters 101.mp3 to text and saved to content/speech_conversion/Apache Superset Dashboard Filters 101.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted GPT x Superset.mp3 to text and saved to content/speech_conversion/GPT x Superset.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted Superset 210 Meetup.mp3 to text and saved to content/speech_conversion/Superset 210 Meetup.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted Live Demo Syncing databases datasets and metrics from dbt.mp3 to text and saved to content/speech_conversion/Live Demo Syncing databases datasets and metrics from dbt.txt\n",
            "Converted Preset Customizable BI for the Modern Data Stack.mp3 to text and saved to content/speech_conversion/Preset Customizable BI for the Modern Data Stack.txt\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "import os\n",
        "\n",
        "# Function to convert audio file to text using Whisper\n",
        "def audio_to_text(audio_path, model):\n",
        "    result = model.transcribe(audio_path)\n",
        "    return result['text']\n",
        "\n",
        "# Load the Whisper model (use 'base' or other available models)\n",
        "model = whisper.load_model('base')\n",
        "\n",
        "# Directory containing the .wav files\n",
        "directory_path = 'downloads/'\n",
        "\n",
        "# Directory to save the .txt files\n",
        "output_directory = 'content/speech_conversion/'\n",
        "\n",
        "# Create the output directory if it does not exist\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "# Loop through all files in the directory\n",
        "for filename in os.listdir(directory_path):\n",
        "    if filename.endswith(\".mp3\"):\n",
        "        audio_path = os.path.join(directory_path, filename)\n",
        "        text = audio_to_text(audio_path, model)\n",
        "\n",
        "        # Save the text to a .txt file\n",
        "        output_path = os.path.join(output_directory, f\"{os.path.splitext(filename)[0]}.txt\")\n",
        "        with open(output_path, 'w') as file:\n",
        "            file.write(text)\n",
        "\n",
        "        print(f\"Converted {filename} to text and saved to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di7llIDIIR-S"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3tNU+t7CwLz54pMP+9amo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}